[2024-05-27 02:02:12,094] {taskinstance.py:851} INFO - Dependencies all met for <TaskInstance: load_init_data.extract_data_from_csv 2024-05-26T02:00:00+00:00 [queued]>
[2024-05-27 02:02:12,112] {taskinstance.py:851} INFO - Dependencies all met for <TaskInstance: load_init_data.extract_data_from_csv 2024-05-26T02:00:00+00:00 [queued]>
[2024-05-27 02:02:12,113] {taskinstance.py:1042} INFO - 
--------------------------------------------------------------------------------
[2024-05-27 02:02:12,113] {taskinstance.py:1043} INFO - Starting attempt 1 of 6
[2024-05-27 02:02:12,113] {taskinstance.py:1044} INFO - 
--------------------------------------------------------------------------------
[2024-05-27 02:02:12,121] {taskinstance.py:1063} INFO - Executing <Task(PythonOperator): extract_data_from_csv> on 2024-05-26T02:00:00+00:00
[2024-05-27 02:02:12,124] {standard_task_runner.py:52} INFO - Started process 1157 to run task
[2024-05-27 02:02:12,128] {standard_task_runner.py:76} INFO - Running: ['airflow', 'tasks', 'run', 'load_init_data', 'extract_data_from_csv', '2024-05-26T02:00:00+00:00', '--job-id', '469', '--pool', 'default_pool', '--raw', '--subdir', 'DAGS_FOLDER/load_init_data.py', '--cfg-path', '/tmp/tmp_ccr3rbt', '--error-file', '/tmp/tmppm3vqi_1']
[2024-05-27 02:02:12,130] {standard_task_runner.py:77} INFO - Job 469: Subtask extract_data_from_csv
[2024-05-27 02:02:12,167] {logging_mixin.py:104} INFO - Running <TaskInstance: load_init_data.extract_data_from_csv 2024-05-26T02:00:00+00:00 [running]> on host 1f334d963743
[2024-05-27 02:02:12,202] {taskinstance.py:1257} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=load_init_data
AIRFLOW_CTX_TASK_ID=extract_data_from_csv
AIRFLOW_CTX_EXECUTION_DATE=2024-05-26T02:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2024-05-26T02:00:00+00:00
[2024-05-27 02:02:12,562] {python.py:118} INFO - Done. Returned value was: None
[2024-05-27 02:02:12,575] {taskinstance.py:1166} INFO - Marking task as SUCCESS. dag_id=load_init_data, task_id=extract_data_from_csv, execution_date=20240526T020000, start_date=20240527T020212, end_date=20240527T020212
[2024-05-27 02:02:12,600] {taskinstance.py:1220} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-05-27 02:02:12,606] {local_task_job.py:146} INFO - Task exited with return code 0
[2024-05-27 21:19:26,323] {taskinstance.py:851} INFO - Dependencies all met for <TaskInstance: load_init_data.extract_data_from_csv 2024-05-26T02:00:00+00:00 [queued]>
[2024-05-27 21:19:26,344] {taskinstance.py:851} INFO - Dependencies all met for <TaskInstance: load_init_data.extract_data_from_csv 2024-05-26T02:00:00+00:00 [queued]>
[2024-05-27 21:19:26,345] {taskinstance.py:1042} INFO - 
--------------------------------------------------------------------------------
[2024-05-27 21:19:26,345] {taskinstance.py:1043} INFO - Starting attempt 1 of 6
[2024-05-27 21:19:26,345] {taskinstance.py:1044} INFO - 
--------------------------------------------------------------------------------
[2024-05-27 21:19:26,363] {taskinstance.py:1063} INFO - Executing <Task(PythonOperator): extract_data_from_csv> on 2024-05-26T02:00:00+00:00
[2024-05-27 21:19:26,369] {standard_task_runner.py:52} INFO - Started process 187 to run task
[2024-05-27 21:19:26,376] {standard_task_runner.py:76} INFO - Running: ['airflow', 'tasks', 'run', 'load_init_data', 'extract_data_from_csv', '2024-05-26T02:00:00+00:00', '--job-id', '499', '--pool', 'default_pool', '--raw', '--subdir', 'DAGS_FOLDER/load_init_data.py', '--cfg-path', '/tmp/tmp3j6t8yiq', '--error-file', '/tmp/tmpmz0bwc42']
[2024-05-27 21:19:26,385] {standard_task_runner.py:77} INFO - Job 499: Subtask extract_data_from_csv
[2024-05-27 21:19:26,434] {logging_mixin.py:104} INFO - Running <TaskInstance: load_init_data.extract_data_from_csv 2024-05-26T02:00:00+00:00 [running]> on host 1f334d963743
[2024-05-27 21:19:26,477] {taskinstance.py:1257} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=load_init_data
AIRFLOW_CTX_TASK_ID=extract_data_from_csv
AIRFLOW_CTX_EXECUTION_DATE=2024-05-26T02:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2024-05-26T02:00:00+00:00
[2024-05-27 21:19:27,037] {python.py:118} INFO - Done. Returned value was: None
[2024-05-27 21:19:27,045] {taskinstance.py:1166} INFO - Marking task as SUCCESS. dag_id=load_init_data, task_id=extract_data_from_csv, execution_date=20240526T020000, start_date=20240527T211926, end_date=20240527T211927
[2024-05-27 21:19:27,068] {taskinstance.py:1220} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-05-27 21:19:27,093] {local_task_job.py:146} INFO - Task exited with return code 0
[2024-05-28 16:24:17,467] {taskinstance.py:851} INFO - Dependencies all met for <TaskInstance: load_init_data.extract_data_from_csv 2024-05-26T02:00:00+00:00 [queued]>
[2024-05-28 16:24:17,484] {taskinstance.py:851} INFO - Dependencies all met for <TaskInstance: load_init_data.extract_data_from_csv 2024-05-26T02:00:00+00:00 [queued]>
[2024-05-28 16:24:17,485] {taskinstance.py:1042} INFO - 
--------------------------------------------------------------------------------
[2024-05-28 16:24:17,485] {taskinstance.py:1043} INFO - Starting attempt 1 of 6
[2024-05-28 16:24:17,485] {taskinstance.py:1044} INFO - 
--------------------------------------------------------------------------------
[2024-05-28 16:24:17,493] {taskinstance.py:1063} INFO - Executing <Task(PythonOperator): extract_data_from_csv> on 2024-05-26T02:00:00+00:00
[2024-05-28 16:24:17,498] {standard_task_runner.py:52} INFO - Started process 197 to run task
[2024-05-28 16:24:17,508] {standard_task_runner.py:76} INFO - Running: ['airflow', 'tasks', 'run', 'load_init_data', 'extract_data_from_csv', '2024-05-26T02:00:00+00:00', '--job-id', '506', '--pool', 'default_pool', '--raw', '--subdir', 'DAGS_FOLDER/load_init_data.py', '--cfg-path', '/tmp/tmps5hhx0w8', '--error-file', '/tmp/tmph1y1l0kj']
[2024-05-28 16:24:17,513] {standard_task_runner.py:77} INFO - Job 506: Subtask extract_data_from_csv
[2024-05-28 16:24:17,559] {logging_mixin.py:104} INFO - Running <TaskInstance: load_init_data.extract_data_from_csv 2024-05-26T02:00:00+00:00 [running]> on host a3c9b0e21f74
[2024-05-28 16:24:17,603] {taskinstance.py:1257} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=load_init_data
AIRFLOW_CTX_TASK_ID=extract_data_from_csv
AIRFLOW_CTX_EXECUTION_DATE=2024-05-26T02:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2024-05-26T02:00:00+00:00
[2024-05-28 16:24:18,028] {python.py:118} INFO - Done. Returned value was: None
[2024-05-28 16:24:18,040] {taskinstance.py:1166} INFO - Marking task as SUCCESS. dag_id=load_init_data, task_id=extract_data_from_csv, execution_date=20240526T020000, start_date=20240528T162417, end_date=20240528T162418
[2024-05-28 16:24:18,115] {taskinstance.py:1220} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-05-28 16:24:18,143] {local_task_job.py:146} INFO - Task exited with return code 0
[2024-06-09 14:01:21,124] {taskinstance.py:851} INFO - Dependencies all met for <TaskInstance: load_init_data.extract_data_from_csv 2024-05-26T02:00:00+00:00 [queued]>
[2024-06-09 14:01:21,193] {taskinstance.py:851} INFO - Dependencies all met for <TaskInstance: load_init_data.extract_data_from_csv 2024-05-26T02:00:00+00:00 [queued]>
[2024-06-09 14:01:21,199] {taskinstance.py:1042} INFO - 
--------------------------------------------------------------------------------
[2024-06-09 14:01:21,211] {taskinstance.py:1043} INFO - Starting attempt 1 of 6
[2024-06-09 14:01:21,219] {taskinstance.py:1044} INFO - 
--------------------------------------------------------------------------------
[2024-06-09 14:01:21,263] {taskinstance.py:1063} INFO - Executing <Task(PythonOperator): extract_data_from_csv> on 2024-05-26T02:00:00+00:00
[2024-06-09 14:01:21,290] {standard_task_runner.py:52} INFO - Started process 187 to run task
[2024-06-09 14:01:21,315] {standard_task_runner.py:76} INFO - Running: ['airflow', 'tasks', 'run', 'load_init_data', 'extract_data_from_csv', '2024-05-26T02:00:00+00:00', '--job-id', '11', '--pool', 'default_pool', '--raw', '--subdir', 'DAGS_FOLDER/load_init_data.py', '--cfg-path', '/tmp/tmpaxga6p78', '--error-file', '/tmp/tmpb88p0xhe']
[2024-06-09 14:01:21,327] {standard_task_runner.py:77} INFO - Job 11: Subtask extract_data_from_csv
[2024-06-09 14:01:21,487] {logging_mixin.py:104} INFO - Running <TaskInstance: load_init_data.extract_data_from_csv 2024-05-26T02:00:00+00:00 [running]> on host 97b873bf6d4d
[2024-06-09 14:01:21,644] {taskinstance.py:1257} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=load_init_data
AIRFLOW_CTX_TASK_ID=extract_data_from_csv
AIRFLOW_CTX_EXECUTION_DATE=2024-05-26T02:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2024-05-26T02:00:00+00:00
[2024-06-09 14:01:23,327] {python.py:118} INFO - Done. Returned value was: None
[2024-06-09 14:01:23,429] {taskinstance.py:1166} INFO - Marking task as SUCCESS. dag_id=load_init_data, task_id=extract_data_from_csv, execution_date=20240526T020000, start_date=20240609T140121, end_date=20240609T140123
[2024-06-09 14:01:24,017] {taskinstance.py:1220} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-09 14:01:24,118] {local_task_job.py:146} INFO - Task exited with return code 0
